{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ben Smith / Smith (concussion) remains out of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry bout the stream last night I crashed out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Headley's RBI double in the 8th inning o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  \"QT @user In the original draft of the 7th boo...      2\n",
       "1  \"Ben Smith / Smith (concussion) remains out of...      1\n",
       "2  Sorry bout the stream last night I crashed out...      1\n",
       "3  Chase Headley's RBI double in the 8th inning o...      1\n",
       "4  @user Alciato: Bee will invest 150 million in ...      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_file = \"/home/colombelli/temp/applications/ey/data-set/train_complete.csv\"\n",
    "df = pd.read_csv(train_file)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation of the basic dataset properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  47615\n",
      "Labels:\n",
      "1    21542\n",
      "2    18668\n",
      "0     7405\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Tweet NaN values:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \", len(df))\n",
    "print(\"Labels:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nTweet NaN values: \", df['tweet'].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing \n",
    "\n",
    "I will use a baseline approach and compare to a state-of-the-art approach for sentiment analysis. \n",
    "The data preprocessing for the TF-IDF approach used with the baseline algorithm is heavier than the preprocessing performed in the data used by BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/colombelli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                            reduce_len=True)\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# There are lots of these functions available on the internet\n",
    "def text_preprocessing_tfidf(text):\n",
    "\n",
    "    # Remove @mentions\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    # Remove old style retweet text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n",
    "    # Remove the hash # sign from hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "\n",
    "    text_clean = []\n",
    "    for word in tokenizer.tokenize(text):\n",
    "        if (word not in stopwords.words('english') and  # Remove stopwords\n",
    "            word not in string.punctuation):  # Remove punctuation\n",
    "\n",
    "            stem_word = stemmer.stem(word) # happy, happiness, etc -> happi            \n",
    "            text_clean.append(stem_word)\n",
    "\n",
    "    return \" \".join(text_clean)\n",
    "\n",
    "\n",
    "# This process can take some time and could be improved\n",
    "def get_tfidf_preprocessed_dataset(df):\n",
    "    df['tweet'] = df['tweet'].\\\n",
    "        map(text_preprocessing_tfidf)\n",
    "    #df.loc[:,'tweet'] = tweet_preprocessed_series\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34761/550669915.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qt origin draft 7th book remu lupin surviv bat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ben smith smith concuss remain lineup thursday...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sorri bout stream last night crash tonight sur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chase headley' rbi doubl 8th inning david pric...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alciato bee invest 150 million januari anoth 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  qt origin draft 7th book remu lupin surviv bat...      2\n",
       "1  ben smith smith concuss remain lineup thursday...      1\n",
       "2  sorri bout stream last night crash tonight sur...      1\n",
       "3  chase headley' rbi doubl 8th inning david pric...      1\n",
       "4  alciato bee invest 150 million januari anoth 2...      2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = get_tfidf_preprocessed_dataset(df.iloc[:50, :])\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        qt origin draft 7th book remu lupin surviv bat...\n",
       "1        ben smith smith concuss remain lineup thursday...\n",
       "2        sorri bout stream last night crash tonight sur...\n",
       "3        chase headley' rbi doubl 8th inning david pric...\n",
       "4        alciato bee invest 150 million januari anoth 2...\n",
       "                               ...                        \n",
       "47610    london ap princ georg celebr second birthday w...\n",
       "47611    harper' worst offens refuge may climat record ...\n",
       "47612    hold ... sam smith may theme spectr dope 007 s...\n",
       "47613    gonna watch final destin 5 tonight alway leav ...\n",
       "47614    interview devon alexand speed kill video tuesd...\n",
       "Name: tweet, Length: 47615, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c45e1f0298c01ac4f8be2f521cf2a42bd379637c40f3552ecde96cd73c3a374"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
